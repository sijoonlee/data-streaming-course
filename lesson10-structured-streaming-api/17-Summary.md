## Lesson Summary
In this lesson, we learned the basic but most useful operations that can be applied to Spark RDDs and DataFrames. We covered in depth how lazy evaluation is built into Sparkâ€™s transformations and how it can affect the overall performance of the application.

We have also started to learn operations that could be applied to Spark Streaming and Structured Streaming. These will be useful in the next lesson, and at your job. In the next lesson we will continue to learn about Structured Streaming, and what kind of methods we can use to fine tune the application to satisfy your business needs.

## Further Optional Research
In case you are interested in learning more about any of these topics, here are some good resources for you!

- [Action/Transformations](https://medium.com/@aristo_alex/how-apache-sparks-transformations-and-action-works-ceb0d03b00d0)
- [Stream-Stream JOINs](https://databricks.com/blog/2018/03/13/introducing-stream-stream-joins-in-apache-spark-2-3.html)
- [Spark journal](https://cacm.acm.org/magazines/2016/11/209116-apache-spark/abstract)
- [Spark SQL journal](https://cs.stanford.edu/~matei/papers/2015/sigmod_spark_sql.pdf)
- [Catalyst Optimizer](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)